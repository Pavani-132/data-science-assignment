# Primary LLM Provider (Google Gemini - FREE)
GEMINI_API_KEY=AIzaSyC6je1ziWKBNLMMMazRgfxzFw144BQrAXI

# Backup LLM Providers (Optional - have quota issues)
OPENAI_API_KEY=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

# LLM Configuration
GEMINI_MODEL=gemini-2.5-flash
OPENAI_MODEL=gpt-4o
TEMPERATURE=0.3

# Fallback Configuration
USE_FALLBACK=true

# API Configuration
API_HOST=localhost
API_PORT=8000
